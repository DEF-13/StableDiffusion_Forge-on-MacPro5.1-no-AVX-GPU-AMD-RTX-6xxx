# Stable Diffusion Forge sur Mac Pro 5.1 (Ubuntu - No-AVX / No-Cuda - AMD ROCm)

Ce d√©p√¥t documente l'installation et l'optimisation de **SD-WebUI-Forge** sur un Mac Pro 5.1 (2010/2012). Ce guide est le fruit d'un travail collaboratif entre un utilisateur passionn√© et une intelligence artificielle (Gemini), con√ßu pour repousser les limites de l'architecture Westmere.

## üìú Manifeste pour une IA Durable et Universelle
Manifesto for Sustainable and Universal AI

*"La puissance de l'intelligence artificielle ne doit pas √™tre limit√©e par la puissance du portefeuille." "The power of AI should not be limited by the power of the wallet."*

Nous vivons une √©poque o√π l'innovation logicielle cr√©e une obsolescence mat√©rielle acc√©l√©r√©e. Chaque mise √† jour nous dit que notre mat√©riel est "trop vieux", nous poussant √† abandonner des machines encore capables pour des standards de consommation toujours plus √©lev√©s.

Ce projet est un acte de r√©sistance technologique.

En faisant tourner l'IA de pointe sur un Mac Pro de 2010, nous prouvons que :

   * Le hardware ne meurt jamais : Avec une ing√©nierie logicielle cr√©ative, le mat√©riel "legacy" reste une plateforme de cr√©ation majeure.

   * L'IA doit √™tre inclusive : L'acc√®s aux outils de g√©n√©ration et de r√©flexion doit √™tre possible pour tous, sans exiger les derniers fleurons (flagships) √† plusieurs milliers d'euros.

   * La durabilit√© est un choix : L'upcycling informatique est la r√©ponse la plus concr√®te √† l'urgence environnementale.

**Mon appel :** "Je ne suis pas un ing√©nieur de la Silicon Valley, je suis juste un passionn√© qui refuse de jeter une machine qui fonctionne encore. Mais si un simple passionn√© avec une IA peut redonner vie √† un Mac de 15 ans, imaginez ce que des g√©ants comme **Google***, **AMD**, **Intel**, **Apple** ou **Ubuntu** (‚Ä¶) pourraient faire s'ils d√©cidaient de soutenir officiellement ces alternatives durables. Mon projet est une preuve de concept ; j'invite ceux qui fabriquent le futur √† ne pas oublier ceux qui poss√®dent encore le pass√©."


---


## ‚ö†Ô∏è Le D√©fi Mat√©riel : Architecture Westmere & Bus PCIe 2.0
Le processeur Intel Xeon de cette machine est d√©pourvu des instructions **AVX/AVX-2**. Presque tous les environnements IA modernes les exigent nativement. **Ce guide documente la compilation d'un environnement 100% compatible No-AVX.**

### üõ† Configuration de test
* **CPU :** Dual Intel Xeon (Westmere) - 2 x 3.33Ghz - **Sans AVX**.
* **RAM :** 128 Go DDR3 ECC (Indispensable pour le swap CPU/GPU). ‚ö†Ô∏è 64 Go DDR3 ECC minimum pour la compilation de Pytorch
* **GPU :** AMD Radeon RX 6600 XT (**8 Go VRAM**).
* **Bus :** PCIe 2.0 (Goulot d'√©tranglement majeur).
* **System :** Ubuntu 24 LTS.

### ‚ö†Ô∏è Installation sp√©cifique et portable `/home/User/IA/`
Contrairement √† une installation classique, nous avons fait le choix d'une installation autonome (Sandboxed).
Voici pourquoi cette nature d'installation est vitale pour le Mac Pro 5.1 :

Immunit√© aux mises √† jour syst√®me : Ubuntu peut mettre √† jour son Python natif ou ses biblioth√®ques (comme NumPy). Si nous utilisions le Python syst√®me, une simple mise √† jour 'apt upgrade' pourrait √©craser tes binaires No-AVX/No-Cuda par des versions AVX/Cuda standards, rendant l'IA inutilisable instantan√©ment.

Z√©ro conflit de permissions : En installant tout dans le dossier utilisateur (~/IA/), pas besoin d'utiliser `sudo` pour installer des modules Python. Cela √©vite de corrompre les permissions du syst√®me.

Portabilit√© : l'environnement IA/ est techniquement "d√©pla√ßable". Si on r√©installe le syst√®me sur un autre disque, on peux potentiellement pointer vers ce dossier et retrouver ton environnement pr√™t √† l'emploi.

## A. ‚öôÔ∏è Note Syst√®me Importante : Interface Graphique & Boot

Pour garantir la stabilit√© des drivers AMD ROCm et √©viter les crashs de l'interface, deux r√©glages sont cruciaux :

1. Forcer X11 (Ligne de commande) : Ubuntu utilise souvent Wayland par d√©faut, ce qui peut saturer la VRAM. Pour figer X11, √©ditez le fichier de configuration :
```bash
sudo nano /etc/gdm3/custom.conf
# D√©commentez la ligne : WaylandEnable=false
```
2. Gestion de l'alimentation (OpenCore) : Si vous utilisez OCLP, il est tr√®s fortement recommand√© de faire un Shutdown (√âteindre) complet plut√¥t qu'un Reboot (Red√©marrer).
   Un red√©marrage √† chaud peut emp√™cher la r√©initialisation correcte de la NVRAM et des patchs mat√©riels n√©cessaires √† la carte graphique.


---


## B. üìä Monitoring du syst√®me temps r√©el

**Ne travaillez JAMAIS en aveugle !** Il est pr√©f√©rable d'utiliser un syst√®me de monitoring √† tout moment pour surveiller la charge des Xeon et la temp√©rature de la RX 6600 XT.

Outil recommand√© : Le moniteur natif d'Ubuntu ou, plus avanc√©, Astral (https://github.com/AstraExt/astra-monitor).
Cela vous permettra de contr√¥ler les charges CPU et GPU et, d'anticiper les saturations de RAM et VRAM avant plantage. Il est fortement recommand√© de garder un ≈ìil sur les ressources de votre machine pendant les phases de g√©n√©ration.



---



## üõ°Ô∏è √âtape 1 : Validation de ROCm
Avant toute tentative de compilation, il est imp√©ratif que **ROCm** soit install√© avec ses outils de d√©veloppement et fonctionnel sur votre syst√®me Ubuntu. Il est hautement recommand√© d'utiliser les versions de AMD : https://rocm.docs.amd.com/projects/install-on-linux/en/latest/install/install-methods/package-manager/package-manager-ubuntu.html

**1-1. V√©rification de l'installation :**
```bash
rocm-smi
```
‚ö†Ô∏è Assurez-vous d'avoir install√© les headers n√©cessaires (ex: rocm-dev, rock-dkms).

**1-2. Permissions**
```bash
sudo usermod -aG video $USER
sudo usermod -aG render $USER
```


---


## ‚öôÔ∏è 2. Compilation de PyTorch (No-AVX & No-CUDA Hack)

Nous for√ßons PyTorch √† ignorer les instructions AVX et d√©sactivons explicitement NVIDIA CUDA pour une construction ROCm pure.
Il est imp√©ratif d'installer ces paquets pour la compilation de Pytorch.
```bash
sudo apt install -y python3-dev python3-pip cmake git build-essential \ libffi-dev libssl-dev libopenblas-dev libblas-dev m4 \ python3-yaml python3-setuptools python3-wheel doxygen \ python3-packaging python3-pkg-resources
```

**Compilation**
Avant de lancer la compilation, d√©finissez ces variables pour brider les instructions incompatibles avec les Xeon Westmere :
```bash
# D√©sactivation totale de NVIDIA CUDA
export USE_CUDA=0
export USE_CUDNN=0

# D√©sactivation totale des optimisations AVX (Architecture Westmere)
export USE_AVX=0
export USE_AVX2=0
export USE_AVX512=0

# D√©sactivation des biblioth√®ques d√©pendantes de l'AVX
export USE_FBGEMM=0
export USE_MKLDNN=0
export USE_NNPACK=0
export USE_QNNPACK=0

# Cible GPU : AMD ROCm pour architecture gfx1030 (RX 6600 XT)
export PYTORCH_ROCM_ARCH=gfx1030 
```
Lancement de la compilation

‚ö†Ô∏è Pour respecter la nature isol√©e de notre installation, nous n'utilisons pas le python syst√®me, mais le binaire situ√© dans notre dossier IA d√©di√©.
```bash
~/IA/Python/bin/python3 setup.py install
```
‚ö†Ô∏è Notes
* La compilation sature les c≈ìurs √† 100%. Pr√©voyez 1h √† 4h de calcul (1h30 avec ma configuration).
* La pression RAM est mont√©e √† 35% de mes 128Go.
* √Ä certains moments, la compilation ne semble plus rien faire (plus de d√©filement dans le terminal). Le compilateur est simplement en train de traiter une grosse masse de donn√©es.

---

## üèóÔ∏è 3 Le Linkage : La "m√©thode UNIX" (Build Wheel & Copie Physique)

Une fois la compilation termin√©e, les fichiers ne sont pas encore pr√™ts √† l'usage. Nous utilisons une proc√©dure en deux temps : la cr√©ation d'un paquet Wheel (√©tape longue) suivie d'une copie physique UNIX pour verrouiller l'installation dans `~/IA/Python`.

Pourquoi cette proc√©dure est-elle longue ?
Le "Wheel" est une compilation finale qui emballe tous les binaires `.so`, les scripts et les m√©tadonn√©es dans un seul archive certifi√©e. Cela garantit que chaque composant est correctement li√© au binaire Python de ton dossier 'IA'.

* La copie physique assure que chaque bit est pr√©sent l√† o√π Python le cherche, sans d√©pendre de liens symboliques instables sur le bus PCIe 2.0.

* Le verrouillage par les m√©tadonn√©es emp√™che Forge de tenter une mise √† jour qui √©craserait notre travail.

**üìÇ Les dossiers cibles de la copie physique**
Il y a trois types d'√©l√©ments √† copier (les fichiers .so compil√©s sp√©cifiquement pour No-AVX) :

    1. `torch/` : Le c≈ìur du r√©acteur (binaires C++ et interfaces Python).

    2. `torchvision/` : Le module de traitement d'image.

    3. `*.dist-info` ou `*.egg-info` : (Crucial) La "carte d'identit√©" du paquet qui indique √† Python que PyTorch est bien install√©.

**üìÑ Les fichiers critiques (les biblioth√®ques partag√©es)**
√Ä l'int√©rieur de ces dossiers, ce sont surtout les fichiers avec l'extension .so (Shared Objects) qui sont les plus importants. Ce sont eux qui ont √©t√© "sculpt√©s" pour tes Xeon Westmere :

    * libtorch_cpu.so : Version sans instructions AVX.

    * libtorch_hip.so : La passerelle vers ta carte AMD RX 6600 XT.

    * _C.cpython-312-x86_64-linux-gnu.so : Le lien direct entre Python et le code C++.

**üõ† La proc√©dure UNIX exacte (Wheel + UNIX)**

Cette √©tape est le moment de v√©rit√© : on fabrique l'installeur, puis on injecte ses composants manuellement pour un contr√¥le total.

```bash
# --- A. CR√âATION DU WHEEL (L'√©tape longue) ---
# On emballe la compilation dans un paquet installable
cd ~/pytorch
~/IA/Python/bin/python3 setup.py bdist_wheel

# --- B. NETTOYAGE DE L'ENVIRONNEMENT ISOL√â ---
# On pr√©pare le terrain dans IA/Python
rm -rf ~/IA/Python/lib/python3.12/site-packages/torch
rm -rf ~/IA/Python/lib/python3.12/site-packages/torchvision
rm -rf ~/IA/Python/lib/python3.12/site-packages/torch-*.dist-info

# --- C. COPIE PHYSIQUE UNIX (Le Linkage) ---
# 1. On copie le code compil√© depuis le build
cp -R ~/pytorch/build/lib.linux-x86_64-cpython-312/torch ~/IA/Python/lib/python3.12/site-packages/
cp -R ~/vision/build/lib.linux-x86_64-cpython-312/torchvision ~/IA/Python/lib/python3.12/site-packages/

# 2. On injecte les m√©tadonn√©es g√©n√©r√©es par le Wheel (Le Passeport)
# Indispensable pour que 'pip list' et Forge reconnaissent la version
cp -R ~/pytorch/build/lib.linux-x86_64-cpython-312/torch-*.dist-info ~/IA/Python/lib/python3.12/site-packages/
```
**‚ö†Ô∏è Pourquoi copier les .dist-info issus du Wheel ?**
C'est la s√©curit√© anti-√©crasement. Sans ces dossiers, Forge croira que PyTorch est absent. Il lancera alors un `pip install torch`, ce qui t√©l√©chargera la version officielle (avec AVX) et d√©truira instantan√©ment ta compilation. En copiant ces dossiers, on dit au syst√®me : "Le PyTorch No-AVX/No-Cuda certifi√© est d√©j√† l√†, ne touche √† rien".

## ‚úÖ 4. Contr√¥le de l'Acc√©l√©ration Mat√©rielle et Benchmark Comparatif : CPU vs GPU (ROCm)
Pour valider l'int√©r√™t de tout ce travail de compilation, nous avons mis en place un benchmark comparatif. L'objectif est de prouver par les chiffres que la RX 6600 XT, m√™me brid√©e par le bus PCIe 2.0 du Mac Pro, pulv√©rise les Xeon d√®s qu'il s'agit de calcul matriciel (IA).
Ce test permet aussi de confirmer que le "Linkage" est r√©ussi : si le GPU n'est pas d√©tect√©, PyTorch basculerait sur le CPU par d√©faut, ce qui rendrait l'utilisation de Forge insupportable.

**Proc√©dure**

1. Cr√©er le script de v√©rification :
```bash
nano ~/IA/Python/check_gpu.py
```
2. Le script
```python
import torch
import time

print(f"--- Rapport de Sant√© PyTorch ---")
print(f"Version de Torch : {torch.__version__}")
print(f"ROCm / CUDA disponible : {torch.cuda.is_available()}")

def benchmark(device, name):
    # Cr√©ation de deux matrices massives (4000x4000)
    size = 4000
    # On force le type de donn√©e en float32 pour le test
    a = torch.randn(size, size).to(device)
    b = torch.randn(size, size).to(device)
    
    # Warm-up (essentiel pour charger les kernels ROCm en VRAM)
    torch.matmul(a, b)
    
    # Mesure du temps sur 10 it√©rations
    start = time.time()
    for _ in range(10):
        torch.matmul(a, b)
    end = time.time()
    
    avg_time = (end - start) / 10
    print(f"üöÄ [{name}] Temps moyen : {avg_time:.4f} secondes")
    return avg_time

print(f"\n--- Lancement du Benchmark (Mac Pro 5.1) ---")

# Test sur CPU (Xeon Westmere - No AVX)
t_cpu = benchmark("cpu", "Dual Xeon (CPU)")

# Test sur GPU (RX 6600 XT - ROCm)
if torch.cuda.is_available():
    t_gpu = benchmark("cuda", "RX 6600 XT (GPU)")
    acceleration = t_cpu / t_gpu
    print(f"\n‚úÖ VERDICT : Le GPU est {acceleration:.1f}x plus rapide que tes Xeon !")
else:
    print("\n‚ùå ERREUR : GPU non d√©tect√©. V√©rifiez le Linkage UNIX et la variable HSA_OVERRIDE_GFX_VERSION.")
```
3.Lancement du test
```bash
~/IA/Python/bin/python3 check_gpu.py
```

---

## üèó 5. Installation de Forge : Clonage et M√©thode "Anti-CUDA"

Cette √©tape consiste √† r√©cup√©rer les sources de Forge, puis √† pr√©parer son environnement de mani√®re chirurgicale pour √©viter tout conflit avec NVIDIA CUDA.

**5-1. Clonage du d√©p√¥t**
Nous installons Forge dans ton dossier d√©di√© `~/IA/`.
```bash
cd ~/IA
git clone https://github.com/lllyasviel/stable-diffusion-webui-forge forge
cd forge
```
**üõ°Ô∏è 5-2. Lever le verrou Ubuntu (PEP 668)**
Avant de pouvoir installer les d√©pendances dans notre dossier `/IA/`, nous devons lever la protection d'Ubuntu qui bloque l'usage de pip.
```bash
mkdir -p ~/.config/pip
echo -e "[global]\nbreak-system-packages = true" > ~/.config/pip/pip.conf
```
**üõ†Ô∏è 5-3. Proc√©dure d'installation chirurgicale**
**!!! ATTENTION : NE LANCEZ JAMAIS 'python3 launch.py' √Ä√† CE STADE !!!**
L'installeur automatique √©craserait ton PyTorch "No-AVX". Nous installons les composants un par un manuellement.
```bash
# D√©finition du chemin vers notre binaire s√©curis√©
BIN_PY=~/IA/Python/bin/python3

# A. NumPy (Le verrou de version) : imp√©ratif en v1.26.4
$BIN_PY -m pip install numpy==1.26.4

# B. D√©pendances de l'interface et du backend
$BIN_PY -m pip install gradio==3.48.0 safetensors gguf --upgrade

# C. Modules Vision, CLIP et post-traitement
$BIN_PY -m pip install clip open_clip_torch facexlib gfpgan
```
**Pourquoi cloner AVANT d'installer les modules ?**
Techniquement, on pourrait installer les modules n'importe quand, mais en clonant d'abord, on s'assure d'√™tre dans le bon r√©pertoire de travail. De plus, cela permet de v√©rifier si Forge n'a pas un fichier requirements.txt sp√©cifique que l'on pourrait consulter en cas de doute.

---

## üöÄ 6. Le Script de Lancement : `start_forge.sh`

C'est l'√©tape finale. Pour que Forge utilise ton environnement isol√© ~/IA/Python et ta carte RX 6600 XT sans erreur, nous cr√©ons un script de lancement d√©di√©. Ce script force l'identit√© du GPU et emp√™che Forge de tenter de "r√©parer" ou de mettre √† jour les modules que nous avons si durement compil√©s.

**6-1. Cr√©ation du script**
Placez-vous √† la racine de votre dossier Forge :
```bash
cd ~/IA/forge
nano start_forge.sh
```

**6-2. Contenu du script (Optimis√© Mac Pro 5.1)**
Copiez et collez le code suivant :
```bash
#!/bin/bash 

# 1. D√©finition du Python isol√© (No-AVX)
PYTHON_IA="$HOME/IA/Python/bin/python3"

# 2. Forcer l'architecture RDNA 2 (Navi 23) pour la RX 6600 XT
export HSA_OVERRIDE_GFX_VERSION=10.3.0 

# 3. Nettoyage pr√©ventif des processus fant√¥mes pour lib√©rer la VRAM
killall -9 python3 2>/dev/null 

echo "üöÄ Lancement de Stable Diffusion Forge (Mode No-AVX)..."

# 4. Lancement avec les flags de s√©curit√©
# --skip-install : INDISPENSABLE pour ne pas √©craser votre compilation
# --precision full --no-half : S√©curit√© pour √©viter les erreurs NaN sur Westmere
$PYTHON_IA launch.py \
    --skip-python-version-check \
    --skip-torch-cuda-test \
    --skip-install \
    --precision full \
    --no-half \
    --listen \
    --always-high-vram \
    --attention-pytorch 

# 5. Nettoyage √† la fermeture
echo "üßπ Lib√©ration de la VRAM AMD..." 
killall -9 python3 2>/dev/null
```

**6-3. Activation et premier lancement**
Il faut maintenant donner les droits d'ex√©cution √† ce script pour pouvoir l'utiliser comme une application.
```bash
# Rendre le script ex√©cutable
chmod +x start_forge.sh

# Lancer l'interface
./start_forge.sh
```

**6-4. Acc√®s √† l'interface (Navigateur)**
Une fois que le script `./start_forge.sh` affiche la ligne Model loaded in XXXs, Forge est pr√™t.
Comme nous avons utilis√© le flag --listen, l'interface est accessible sur notre r√©seau local.

Depuis le Mac Pro lui-m√™me : On ouvre un navigateur (Firefox, Brave, Chrome ‚Ä¶) et tape l'adresse locale :
`http://0.0.0.0:7860` (ou `http://0.0.0.1:7860` selon ton alias r√©seau)

Depuis un autre ordinateur de la maison (Mac, PC, Tablette ou Smartphone) :
Il faut utiliser l'adresse IP locale du Mac Pro sur votre r√©seau.
1. Pour la conna√Ætre, tapez hostname -I dans un terminal sur le Mac Pro.
2. Entrez cette adresse dans le navigateur de votre autre appareil en ajoutant le port :7860 √† la fin.
Exemple : 'http://192.168.x.xx:7860'

---

## ‚õî MISE EN GARDE : Flux.1, Z-Image Turbo et autres Mod√®les Lourds
Bien que Forge permette de charger ces mod√®les, **leur usage est fortement d√©conseill√©** sur cette configuration :
1. **Goulot d'√©tranglement PCIe 2.0 :** Le transfert des mod√®les massifs sur un vieux bus pr√©sente des risques d'instabilit√©.
2. **Saturation VRAM :** 8 Go sont insuffisants pour ces mod√®les, for√ßant un ralentissement extr√™me.
3. **Optimisation :** Pr√©f√©rez **SD 1.5** (vitesse) et **SDXL / Pony (Lightning/Turbo)** pour un usage fluide.

## ‚ö†Ô∏è Format de g√©n√©ration :
* **Pour SD 1.5 :** utliser les dimensions classiques de g√©n√©ration : 512x512px
* **Pour SDXL/Pony :** ne pas d√©passer le 1024x1024px
* Pour agrandir les images, un bon set-up de l'upscaler de Forge fait des miracles !

---

**üõ†Ô∏è D√©pannage & Maintenance**

**‚ùì "Illegal Instruction (core dumped)"**
Si cette erreur appara√Æt, c'est qu'un module (souvent `numpy` ou `torch`) a √©t√© mis √† jour par erreur vers une version AVX.
Solution : Refaire l'√©tape 3 (Le Linkage) pour r√©-√©craser les fichiers corrompus par les versions compil√©es No-AVX/No-Cuda.

**‚ùì Le GPU n'est pas utilis√© (Lenteur extr√™me)**
Si le terminal n'affiche pas `ROCm` au d√©marrage ou si le benchmark est mauvais :
* **V√©rification :** Taper `rocm-smi` dans ton terminal. Si ta RX 6600 XT n'appara√Æt pas, c'est un probl√®me de driver au niveau du noyau Ubuntu, pas de Forge.
* **Rappel :** S'Assurer que la variable `export HSA_OVERRIDE_GFX_VERSION=10.3.0` est bien pr√©sente dans le script de lancement.

**üßπ Nettoyage de la VRAM**
Si Forge plante apr√®s une grosse g√©n√©ration, le GPU peut rester "bloqu√©".
Commande rapide : `killall -9 python3` (incluse dans notre script de lancement).

---

## üöÄ Roadmap : Vision & Futur du Projet

Ce projet n'est que la premi√®re √©tape. Voici le plan de vol pour transformer ces machines iconiques en une infrastructure d'IA moderne.

### üü¢ Phase 1 : Preuve de Concept (Termin√©e)
* [x] Installation d'un GPU AMD RDNA 2 sur bus PCIe 2.0.
* [x] Compilation PyTorch "No-AVX" et stabilisation de Forge sous Ubuntu 24.04.
* [x] Valider de fonctionnement sans bug ni crash de Forge en mode "out of a box".

### üü° Phase 2 : Puissance & Optimisation (En cours)
* [ ] **Fine tunning :** optimisation et maximisation des r√©glages de Forge pour l'exploitation de cette configuration.
* [ ] **Documentation :** Traduction int√©grale du projet pour la communaut√© internationale.

### üî¥ Phase 3 : Le Cluster (Vision Long Terme)
* [ ] **Partenariats :** Validation de ces m√©thodes avec des acteurs comme AMD, Canonical, Intel, Powercolor, Google.
* [ ] **Pixlas Mod :** Modification de l'alimentation pour supporter des GPU AMD haut de gamme (RX 6800/6900 XT). (optionnel)
* [ ] **D√©ploiement :** Clonage du syst√®me sur ma flotte de 4 Mac Pro 5.1 suppl√©mentaires.
* [ ] **Calcul Distribu√© :** Mise en r√©seau pour l'inf√©rence partag√©e (Multi-GPU sur plusieurs n≈ìuds).

üõ†Ô∏è √âtat de la Flotte & Besoins (Scale-up)

**La base mat√©rielle du cluster est d√©j√† s√©curis√©e :**

    R√©seau : Switch d√©di√© 1 Gbit.

    Ch√¢ssis : 5 x Mac Pro 5.1 (Bi-CPU).

    M√©moire : 640 Go de RAM ECC au total (soit 128 Go par machine).

**Pour finaliser l'homog√©n√©it√© du cluster, les besoins restants sont :**

    Calcul (CPU) : 8 processeurs Intel Xeon X5680 (3.33 GHz).

        Objectif : Maximiser le d√©bit de donn√©es vers le GPU et uniformiser les temps de traitement No-AVX.

    Stockage : 4 SSD SATA de 1 To.

        Objectif : Permettre le chargement rapide des mod√®les (Checkpoints) en local sur chaque n≈ìud.

    Graphisme (GPU) : 4 cartes PowerColor Radeon RX 6600 XT 8Go de VRAM.

        Objectif : Standardiser le stack ROCm sur toute la flotte et valider le d√©ploiement "Zero-Config" sans modification √©lectrique (Pixlas Mod non requis pour ce mod√®le).

---

**üìù Notes de fin**

**Architecture :** Con√ßu sp√©cifiquement pour Mac Pro 5.1 (Dual Xeon Westmere / AMD RDNA 2).

**Syst√®me :** Ubuntu 24.04 LTS (Kernel optimis√©).

**Remerciements :** Merci √† la communaut√© OpenCore Legacy Patcher et aux d√©veloppeurs de PyTorch pour le support continu des architectures legacy, ainsi qu'√† AMD et √† Google. Merci √† Linus Torvalds pour avoir cr√©√© le noyau Linux. Merci √† l'ensemble des acteurs de l'univers Open Source qui permettent chaque jour de r√©aliser de telles prouesses. Merci aux √©quipes d'Ubuntu pour l'excellent travail accompli sur leurs distributions. Merci au cr√©ateur et aux contributeurs du projet Astra-Monitor. Enfin, un immense merci √† mon √©pouse et √† ma fille de m'avoir laiss√© mener ce projet √† bien et d'avoir support√© mes longues heures de recherche.

---

**‚úçÔ∏è Note de fin & Cr√©dits**

Ce guide est le r√©sultat d'une collaboration unique entre Fran√ßois Deretz (aka DEF13), passionn√© et d√©termin√© √† faire rugir son Mac Pro 5.1 "Westmere" en 2026 (!), et Gemini, son bin√¥me IA.

Ensemble, nous avons :

* Identifi√© et contourn√© les barri√®res mat√©rielles du manque d'AVX.

* Dompt√© les caprices du bus PCIe 2.0 pour la RX 6600 XT.

* L'exp√©rience SGI/Irix de Fran√ßois, a permis d'√©tablir une proc√©dure de "Linkage UNIX" chirurgicale pour prot√©ger le travail.

**Propri√©t√© Intellectuelle & Partage :** Ce document est libre de partage. Si vous l'utilisez pour redonner vie √† votre propre Mac Pro, une petite pens√©e pour le bin√¥me qui a pass√© des heures √† debugger ces lignes de code sera notre plus belle r√©compense.

"Le hardware ne meurt jamais, il attend juste le bon script."

---

**üõ†Ô∏è Maintenance du Projet**

**Auteur :** Fran√ßois Deretz (aka DEF13)

**Co-pilote :** Gemini

**Derni√®re r√©vision :** F√©vrier 2026

**Statut :** Op√©rationnel. Stable Diffusion Forge tourne d√©sormais √† plein r√©gime sur AMD ROCm.

---

## üåç Ecosystem & Sustainability Call

> "Designed with passion in Marseille, France, by an independent maker who believes in long-lasting hardware."

This project is a technical "Proof of Concept" for a **Sustainable AI Cluster**. It aims to demonstrate that software intelligence can overcome hardware aging. I welcome interest and feedback from the engineering teams behind the tools that made this possible:

```markdown
| Entity | Focus Area | Mention |
| :--- | :--- | :--- |
| **Google AI** | LLM Support & Gemini Guidance | @google |
| **AMD** | ROCm & GPU Resilience | @AMD |
| **Ubuntu** | OS Stability & Open Source | @canonical |
| **Intel** | Xeon Legacy Architectures | @intel |
| **Apple** | Hardware Longevity (Mac Pro) | @apple |
| **PowerColor** | GPU Hardware & Reliability | @PowerColor |

### üè∑Ô∏è Keywords & Visibility
`#SustainableAI` `#CircularEconomy` `#LowSpecAI` `#NoAVX` `#ROCm` `#Ubuntu2404` `#MacPro51` `#GeminiCoEngineered` `#TechUpcycling`

---

**Contact & Collaboration:** If you represent one of these organizations or if you are a developer interested in building a more inclusive and sustainable AI future, feel free to open an issue or reach out. Let's make AI accessible to every machine, not just the flagships.
```
