# Stable Diffusion Forge sur Mac Pro 5.1 (Ubuntu - No-AVX / No-Cuda - AMD ROCm)

Ce d√©p√¥t documente l'installation et l'optimisation de **SD-WebUI-Forge** sur un Mac Pro 5.1 (2010/2012). Ce guide est le fruit d'un travail collaboratif entre un utilisateur passionn√© et une intelligence artificielle (Gemini), con√ßu pour repousser les limites de l'architecture Westmere.

---

## ‚ö†Ô∏è Le D√©fi Mat√©riel : Architecture Westmere & Bus PCIe 2.0
Le processeur Intel Xeon de cette machine est d√©pourvu des instructions **AVX/AVX-2**. Presque tous les environnements IA modernes les exigent nativement. **Ce guide documente la compilation d'un environnement 100% compatible No-AVX.**

### üõ† Configuration de test
* **CPU :** Dual Intel Xeon (Westmere) - 2 x 3.33Ghz - **Sans AVX**.
* **RAM :** 128 Go DDR3 ECC (Indispensable pour le swap CPU/GPU). ‚ö†Ô∏è 64 Go DDR3 ECC minimum pour la compilation de Pytorch
* **GPU :** AMD Radeon RX 6600 XT (**8 Go VRAM**).
* **Bus :** PCIe 2.0 (Goulot d'√©tranglement majeur).
* **System :** Ubuntu 24 LTS

### ‚ö†Ô∏è Installation sp√©cifique et portable `/home/User/IA/`
Contrairement √† une installation classique, nous avons fait le choix d'une installation autonome (Sandboxed).
Voici pourquoi cette nature d'installation est vitale pour le Mac Pro 5.1 :

Immunit√© aux mises √† jour syst√®me : Ubuntu peut mettre √† jour son Python natif ou ses biblioth√®ques (comme NumPy). Si nous utilisions le Python syst√®me, une simple mise √† jour 'apt upgrade' pourrait √©craser tes binaires No-AVX/No-Cuda par des versions AVX/Cuda standards, rendant l'IA inutilisable instantan√©ment.

Z√©ro conflit de permissions : En installant tout dans le dossier utilisateur (~/IA/), pas besoin d'utiliser `sudo` pour installer des modules Python. Cela √©vite de corrompre les permissions du syst√®me.

Portabilit√© : l'environnement IA/ est techniquement "d√©pla√ßable". Si on r√©installe le syst√®me sur un autre disque, on peux potentiellement pointer vers ce dossier et retrouver ton environnement pr√™t √† l'emploi.

---

## üõ°Ô∏è √âtape 1 : Validation de ROCm
Avant toute tentative de compilation, il est imp√©ratif que **ROCm** soit install√© avec ses outils de d√©veloppement et fonctionnel sur votre syst√®me Ubuntu. Il est autement recommand√© d'utiliser les versions de AMD.

**1-1. V√©rification de l'installation :**
```bash
rocm-smi
```
‚ö†Ô∏è Assurez-vous d'avoir install√© les headers n√©cessaires (ex: rocm-dev, rock-dkms).

**1-2. Permissions**
```bash
sudo usermod -aG video $USER
sudo usermod -aG render $USER
```

---

## ‚öôÔ∏è 2. Compilation de PyTorch (No-AVX & No-CUDA Hack)

Nous for√ßons PyTorch √† ignorer les instructions AVX et d√©sactivons explicitement NVIDIA CUDA pour une construction ROCm pure.
Il est imp√©ratif d'installer ces paquets pour la compilation de Pytorch.
```bash
sudo apt install -y python3-dev python3-pip cmake git build-essential \ libffi-dev libssl-dev libopenblas-dev libblas-dev m4 \ python3-yaml python3-setuptools python3-wheel doxygen \ python3-packaging python3-pkg-resources
```

**Compilation**
Avant de lancer la compilation, d√©finissez ces variables pour brider les instructions incompatibles avec les Xeon Westmere :
```bash
# D√©sactivation totale de NVIDIA CUDA
export USE_CUDA=0
export USE_CUDNN=0

# D√©sactivation totale des optimisations AVX (Architecture Westmere)
export USE_AVX=0
export USE_AVX2=0
export USE_AVX512=0

# D√©sactivation des biblioth√®ques d√©pendantes de l'AVX
export USE_FBGEMM=0
export USE_MKLDNN=0
export USE_NNPACK=0
export USE_QNNPACK=0

# Cible GPU : AMD ROCm pour architecture gfx1030 (RX 6600 XT)
export PYTORCH_ROCM_ARCH=gfx1030 
```
Lancement de la compilation

‚ö†Ô∏è Pour respecter la nature isol√©e de notre installation, nous n'utilisons pas le python syst√®me, mais le binaire situ√© dans notre dossier IA d√©di√©.
```bash
~/IA/Python/bin/python3 setup.py install
```
‚ö†Ô∏è Notes
* La compilation sature les c≈ìurs √† 100%. Pr√©voyez 1h √† 4h de calcul (1h30 avec ma configuration).
* La pression RAM est mont√©e √† 35% de mes 128Go.
* √Ä certains moments, la compilation ne semble plus rien faire (plus de d√©filement dans le terminal). Le compilateur est simplement en train de traiter une grosse masse de donn√©es.

---

## üèóÔ∏è 3 Le Linkage : La "m√©thode UNIX" (Build Wheel & Copie Physique)

Une fois la compilation termin√©e, les fichiers ne sont pas encore pr√™ts √† l'usage. Nous utilisons une proc√©dure en deux temps : la cr√©ation d'un paquet Wheel (√©tape longue) suivie d'une copie physique UNIX pour verrouiller l'installation dans `~/IA/Python`.

Pourquoi cette proc√©dure est-elle longue ?
Le "Wheel" est une compilation finale qui emballe tous les binaires `.so`, les scripts et les m√©tadonn√©es dans un seul archive certifi√©e. Cela garantit que chaque composant est correctement li√© au binaire Python de ton dossier 'IA'.

* La copie physique assure que chaque bit est pr√©sent l√† o√π Python le cherche, sans d√©pendre de liens symboliques instables sur le bus PCIe 2.0.

* Le verrouillage par les m√©tadonn√©es emp√™che Forge de tenter une mise √† jour qui √©craserait notre travail.

**üìÇ Les dossiers cibles de la copie physique**
Il y a trois types d'√©l√©ments √† copier (les fichiers .so compil√©s sp√©cifiquement pour No-AVX) :

    1. `torch/` : Le c≈ìur du r√©acteur (binaires C++ et interfaces Python).

    2. `torchvision/` : Le module de traitement d'image.

    3. `*.dist-info` ou `*.egg-info` : (Crucial) La "carte d'identit√©" du paquet qui indique √† Python que PyTorch est bien install√©.

**üìÑ Les fichiers critiques (les biblioth√®ques partag√©es)**
√Ä l'int√©rieur de ces dossiers, ce sont surtout les fichiers avec l'extension .so (Shared Objects) qui sont les plus importants. Ce sont eux qui ont √©t√© "sculpt√©s" pour tes Xeon Westmere :

    * libtorch_cpu.so : Version sans instructions AVX.

    * libtorch_hip.so : La passerelle vers ta carte AMD RX 6600 XT.

    * _C.cpython-312-x86_64-linux-gnu.so : Le lien direct entre Python et le code C++.

**üõ† La proc√©dure UNIX exacte (Wheel + UNIX)**

Cette √©tape est le moment de v√©rit√© : on fabrique l'installeur, puis on injecte ses composants manuellement pour un contr√¥le total.

```bash
# --- A. CR√âATION DU WHEEL (L'√©tape longue) ---
# On emballe la compilation dans un paquet installable
cd ~/pytorch
~/IA/Python/bin/python3 setup.py bdist_wheel

# --- B. NETTOYAGE DE L'ENVIRONNEMENT ISOL√â ---
# On pr√©pare le terrain dans IA/Python
rm -rf ~/IA/Python/lib/python3.12/site-packages/torch
rm -rf ~/IA/Python/lib/python3.12/site-packages/torchvision
rm -rf ~/IA/Python/lib/python3.12/site-packages/torch-*.dist-info

# --- C. COPIE PHYSIQUE UNIX (Le Linkage) ---
# 1. On copie le code compil√© depuis le build
cp -R ~/pytorch/build/lib.linux-x86_64-cpython-312/torch ~/IA/Python/lib/python3.12/site-packages/
cp -R ~/vision/build/lib.linux-x86_64-cpython-312/torchvision ~/IA/Python/lib/python3.12/site-packages/

# 2. On injecte les m√©tadonn√©es g√©n√©r√©es par le Wheel (Le Passeport)
# Indispensable pour que 'pip list' et Forge reconnaissent la version
cp -R ~/pytorch/build/lib.linux-x86_64-cpython-312/torch-*.dist-info ~/IA/Python/lib/python3.12/site-packages/
```
**‚ö†Ô∏è Pourquoi copier les .dist-info issus du Wheel ?**
C'est la s√©curit√© anti-√©crasement. Sans ces dossiers, Forge croira que PyTorch est absent. Il lancera alors un `pip install torch`, ce qui t√©l√©chargera la version officielle (avec AVX) et d√©truira instantan√©ment ta compilation. En copiant ces dossiers, on dit au syst√®me : "Le PyTorch No-AVX/No-Cuda certifi√© est d√©j√† l√†, ne touche √† rien".

## ‚úÖ 4. Contr√¥le de l'Acc√©l√©ration Mat√©rielle et Benchmark Comparatif : CPU vs GPU (ROCm)
Pour valider l'int√©r√™t de tout ce travail de compilation, nous avons mis en place un benchmark comparatif. L'objectif est de prouver par les chiffres que la RX 6600 XT, m√™me brid√©e par le bus PCIe 2.0 du Mac Pro, pulv√©rise les Xeon d√®s qu'il s'agit de calcul matriciel (IA).
Ce test permet aussi de confirmer que le "Linkage" est r√©ussi : si le GPU n'est pas d√©tect√©, PyTorch basculerait sur le CPU par d√©faut, ce qui rendrait l'utilisation de Forge insupportable.

**Proc√©dure**

1. Cr√©er le script de v√©rification :
```bash
nano ~/IA/Python/check_gpu.py
```
2. Le script
```python
import torch
import time

print(f"--- Rapport de Sant√© PyTorch ---")
print(f"Version de Torch : {torch.__version__}")
print(f"ROCm / CUDA disponible : {torch.cuda.is_available()}")

def benchmark(device, name):
    # Cr√©ation de deux matrices massives (4000x4000)
    size = 4000
    # On force le type de donn√©e en float32 pour le test
    a = torch.randn(size, size).to(device)
    b = torch.randn(size, size).to(device)
    
    # Warm-up (essentiel pour charger les kernels ROCm en VRAM)
    torch.matmul(a, b)
    
    # Mesure du temps sur 10 it√©rations
    start = time.time()
    for _ in range(10):
        torch.matmul(a, b)
    end = time.time()
    
    avg_time = (end - start) / 10
    print(f"üöÄ [{name}] Temps moyen : {avg_time:.4f} secondes")
    return avg_time

print(f"\n--- Lancement du Benchmark (Mac Pro 5.1) ---")

# Test sur CPU (Xeon Westmere - No AVX)
t_cpu = benchmark("cpu", "Dual Xeon (CPU)")

# Test sur GPU (RX 6600 XT - ROCm)
if torch.cuda.is_available():
    t_gpu = benchmark("cuda", "RX 6600 XT (GPU)")
    acceleration = t_cpu / t_gpu
    print(f"\n‚úÖ VERDICT : Le GPU est {acceleration:.1f}x plus rapide que tes Xeon !")
else:
    print("\n‚ùå ERREUR : GPU non d√©tect√©. V√©rifiez le Linkage UNIX et la variable HSA_OVERRIDE_GFX_VERSION.")
```
3.Lancement du test
```bash
~/IA/Python/bin/python3 check_gpu.py
```

---

## üèó 5. Installation de Forge : Clonage et M√©thode "Anti-CUDA"

Cette √©tape consiste √† r√©cup√©rer les sources de Forge, puis √† pr√©parer son environnement de mani√®re chirurgicale pour √©viter tout conflit avec NVIDIA CUDA.

**5-1. Clonage du d√©p√¥t**
Nous installons Forge dans ton dossier d√©di√© `~/IA/`.
```bash
cd ~/IA
git clone https://github.com/lllyasviel/stable-diffusion-webui-forge forge
cd forge
```
**üõ°Ô∏è 5-2. Lever le verrou Ubuntu (PEP 668)**
Avant de pouvoir installer les d√©pendances dans notre dossier `/IA/`, nous devons lever la protection d'Ubuntu qui bloque l'usage de pip.
```bash
mkdir -p ~/.config/pip
echo -e "[global]\nbreak-system-packages = true" > ~/.config/pip/pip.conf
```
**üõ†Ô∏è 5-3. Proc√©dure d'installation chirurgicale**
**!!! ATTENTION : NE LANCEZ JAMAIS 'python3 launch.py' √Ä√† CE STADE !!!**
L'installeur automatique √©craserait ton PyTorch "No-AVX". Nous installons les composants un par un manuellement.
```bash
# D√©finition du chemin vers notre binaire s√©curis√©
BIN_PY=~/IA/Python/bin/python3

# A. NumPy (Le verrou de version) : imp√©ratif en v1.26.4
$BIN_PY -m pip install numpy==1.26.4

# B. D√©pendances de l'interface et du backend
$BIN_PY -m pip install gradio==3.48.0 safetensors gguf --upgrade

# C. Modules Vision, CLIP et post-traitement
$BIN_PY -m pip install clip open_clip_torch facexlib gfpgan
```
**Pourquoi cloner AVANT d'installer les modules ?**
Techniquement, on pourrait installer les modules n'importe quand, mais en clonant d'abord, on s'assure d'√™tre dans le bon r√©pertoire de travail. De plus, cela permet de v√©rifier si Forge n'a pas un fichier requirements.txt sp√©cifique que l'on pourrait consulter en cas de doute.

---

## üöÄ 6. Le Script de Lancement : `start_forge.sh`

C'est l'√©tape finale. Pour que Forge utilise ton environnement isol√© ~/IA/Python et ta carte RX 6600 XT sans erreur, nous cr√©ons un script de lancement d√©di√©. Ce script force l'identit√© du GPU et emp√™che Forge de tenter de "r√©parer" ou de mettre √† jour les modules que nous avons si durement compil√©s.

**6-1. Cr√©ation du script**
Placez-vous √† la racine de votre dossier Forge :
```bash
cd ~/IA/forge
nano start_forge.sh
```

**6-2. Contenu du script (Optimis√© Mac Pro 5.1)**
Copiez et collez le code suivant :
```bash
#!/bin/bash 

# 1. D√©finition du Python isol√© (No-AVX)
PYTHON_IA="$HOME/IA/Python/bin/python3"

# 2. Forcer l'architecture RDNA 2 (Navi 23) pour la RX 6600 XT
export HSA_OVERRIDE_GFX_VERSION=10.3.0 

# 3. Nettoyage pr√©ventif des processus fant√¥mes pour lib√©rer la VRAM
killall -9 python3 2>/dev/null 

echo "üöÄ Lancement de Stable Diffusion Forge (Mode No-AVX)..."

# 4. Lancement avec les flags de s√©curit√©
# --skip-install : INDISPENSABLE pour ne pas √©craser votre compilation
# --precision full --no-half : S√©curit√© pour √©viter les erreurs NaN sur Westmere
$PYTHON_IA launch.py \
    --skip-python-version-check \
    --skip-torch-cuda-test \
    --skip-install \
    --precision full \
    --no-half \
    --listen \
    --always-high-vram \
    --attention-pytorch 

# 5. Nettoyage √† la fermeture
echo "üßπ Lib√©ration de la VRAM AMD..." 
killall -9 python3 2>/dev/null
```

**6-3. Activation et premier lancement**
Il faut maintenant donner les droits d'ex√©cution √† ce script pour pouvoir l'utiliser comme une application.
```bash
# Rendre le script ex√©cutable
chmod +x start_forge.sh

# Lancer l'interface
./start_forge.sh
```

**6-4. Acc√®s √† l'interface (Navigateur)**
Une fois que le script `./start_forge.sh` affiche la ligne Model loaded in XXXs, Forge est pr√™t.
Comme nous avons utilis√© le flag --listen, l'interface est accessible sur notre r√©seau local.

Depuis le Mac Pro lui-m√™me : On ouvre un navigateur (Firefox, Brave, Chrome ‚Ä¶) et tape l'adresse locale :
`http://0.0.0.0:7860` (ou `http://0.0.0.1:7860` selon ton alias r√©seau)

Depuis un autre ordinateur de la maison (Mac, PC, Tablette ou Smartphone) :
Il faut utiliser l'adresse IP locale du Mac Pro sur votre r√©seau.
1. Pour la conna√Ætre, tapez hostname -I dans un terminal sur le Mac Pro.
2. Entrez cette adresse dans le navigateur de votre autre appareil en ajoutant le port :7860 √† la fin.
Exemple : 'http://192.168.x.xx:7860'

---

## ‚õî MISE EN GARDE : Flux.1, Z-Image Turbo et autres Mod√®les Lourds
Bien que Forge permette de charger ces mod√®les, **leur usage est fortement d√©conseill√©** sur cette configuration :
1. **Goulot d'√©tranglement PCIe 2.0 :** Le transfert des mod√®les massifs sur un vieux bus pr√©sente des risques d'instabilit√©.
2. **Saturation VRAM :** 8 Go sont insuffisants pour ces mod√®les, for√ßant un ralentissement extr√™me.
3. **Optimisation :** Pr√©f√©rez **SD 1.5** (vitesse) et **SDXL / Pony (Lightning/Turbo)** pour un usage fluide.
